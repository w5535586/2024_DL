{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入套件、設定function、載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\subprocess.py\", line 1495, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa4 in position 6: invalid start byte\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from dy_resnet import *\n",
    "import torch.nn.functional as F\n",
    "import random, time, torchprofile\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# Define a custom dataset class\n",
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(self, data_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_file (string): Path to the file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Read the data file\n",
    "        with open(data_file, 'r') as file:\n",
    "            self.data = file.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Process each line\n",
    "        line = self.data[idx].strip()\n",
    "        img_path, label = line.split()\n",
    "        # Complete image path\n",
    "        img_path = os.path.join(self.root_dir, img_path)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(label)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class RandomChannelDropout:\n",
    "    def __init__(self):\n",
    "        self.channel_combinations = [\n",
    "            (0, 1, 2),  # RGB\n",
    "            (0, 1),     # RG\n",
    "            (0, 2),     # RB\n",
    "            (1, 2),     # GB\n",
    "            (0,),       # R\n",
    "            (1,),       # G\n",
    "            (2,)        # B\n",
    "        ]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        channels = list(img.split())\n",
    "        chosen_combination = random.choice(self.channel_combinations)\n",
    "        combined_img = Image.merge('RGB', [channels[i] if i in chosen_combination else Image.new('L', img.size) for i in range(3)])\n",
    "        return combined_img\n",
    "\n",
    "# Define transformations\n",
    "\n",
    "#基礎影像處理\n",
    "basic_augmentations = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_augmentations = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(96),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.RandomVerticalFlip(0.1),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    RandomChannelDropout(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_augmentations = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_augmentations = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class DynamicConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
    "        super(DynamicConv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "\n",
    "        # 定義動態卷積核權重和偏置\n",
    "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 根據輸入的channel數量進行權重調整\n",
    "        current_in_channels = x.size(1)\n",
    "        if current_in_channels < self.in_channels:\n",
    "            weight = self.weight[:, :current_in_channels, :, :]\n",
    "        else:\n",
    "            weight = self.weight\n",
    "        \n",
    "        # 應用卷積操作\n",
    "        return F.conv2d(x, weight, self.bias, self.stride, self.padding)\n",
    "\n",
    "is_train = True\n",
    "model_path = \"best_1.pt\"\n",
    "if is_train:\n",
    "    # 選擇ResNet-18作為模型\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.conv1 = DynamicConv2D(in_channels=3, out_channels=64, kernel_size=7, padding=1)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 50)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.conv1 = DynamicConv2D(in_channels=3, out_channels=64, kernel_size=7, padding=1)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 50)\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "train_dataset = ImageNetDataset(data_file='train.txt', root_dir='', transform=train_augmentations)\n",
    "val_dataset = ImageNetDataset(data_file='val.txt', root_dir='', transform=val_augmentations)\n",
    "test_dataset = ImageNetDataset(data_file='test.txt', root_dir='', transform=test_augmentations)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練DynamicConv2D ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #1: 100%|██████████| 990/990 [03:36<00:00,  4.58it/s, accuracy=5.02, loss=3.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Loss: 3.793766, Accuracy: 5.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #1: 100%|██████████| 8/8 [00:00<00:00,  8.15it/s, accuracy=9.33, loss=3.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.5951, Accuracy: 9.33%\n",
      "Best Accuracy: 9.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #2: 100%|██████████| 990/990 [03:35<00:00,  4.60it/s, accuracy=8.63, loss=3.73] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2, Loss: 3.564647, Accuracy: 8.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #2: 100%|██████████| 8/8 [00:01<00:00,  7.85it/s, accuracy=15.3, loss=3.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.2553, Accuracy: 15.33%\n",
      "Best Accuracy: 15.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #3: 100%|██████████| 990/990 [03:37<00:00,  4.56it/s, accuracy=11.7, loss=3.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3, Loss: 3.404045, Accuracy: 11.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #3: 100%|██████████| 8/8 [00:01<00:00,  7.26it/s, accuracy=16.7, loss=3.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.0778, Accuracy: 16.67%\n",
      "Best Accuracy: 16.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #4: 100%|██████████| 990/990 [03:02<00:00,  5.43it/s, accuracy=15, loss=3.13]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4, Loss: 3.239766, Accuracy: 15.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #4: 100%|██████████| 8/8 [00:00<00:00, 12.49it/s, accuracy=18.4, loss=2.99] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.9877, Accuracy: 18.44%\n",
      "Best Accuracy: 18.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #5: 100%|██████████| 990/990 [02:22<00:00,  6.97it/s, accuracy=18.7, loss=3.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5, Loss: 3.050278, Accuracy: 18.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #5: 100%|██████████| 8/8 [00:00<00:00, 12.53it/s, accuracy=24, loss=2.63]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.6294, Accuracy: 24.00%\n",
      "Best Accuracy: 24.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #6: 100%|██████████| 990/990 [02:50<00:00,  5.80it/s, accuracy=22.2, loss=2.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6, Loss: 2.871903, Accuracy: 22.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #6: 100%|██████████| 8/8 [00:01<00:00,  7.60it/s, accuracy=26.4, loss=2.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.4977, Accuracy: 26.44%\n",
      "Best Accuracy: 26.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #7: 100%|██████████| 990/990 [02:46<00:00,  5.94it/s, accuracy=25.8, loss=2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7, Loss: 2.720708, Accuracy: 25.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #7: 100%|██████████| 8/8 [00:01<00:00,  7.17it/s, accuracy=34.2, loss=2.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.4013, Accuracy: 34.22%\n",
      "Best Accuracy: 34.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #8: 100%|██████████| 990/990 [03:41<00:00,  4.47it/s, accuracy=28.5, loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8, Loss: 2.603299, Accuracy: 28.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #8: 100%|██████████| 8/8 [00:01<00:00,  7.63it/s, accuracy=38.4, loss=2.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.1550, Accuracy: 38.44%\n",
      "Best Accuracy: 38.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #9: 100%|██████████| 990/990 [02:57<00:00,  5.57it/s, accuracy=30.5, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9, Loss: 2.512499, Accuracy: 30.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #9: 100%|██████████| 8/8 [00:01<00:00,  6.76it/s, accuracy=40.2, loss=2.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.0336, Accuracy: 40.22%\n",
      "Best Accuracy: 40.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #10: 100%|██████████| 990/990 [03:15<00:00,  5.07it/s, accuracy=32.6, loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10, Loss: 2.426343, Accuracy: 32.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #10: 100%|██████████| 8/8 [00:01<00:00,  7.79it/s, accuracy=35.6, loss=2.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.2339, Accuracy: 35.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #11: 100%|██████████| 990/990 [03:23<00:00,  4.87it/s, accuracy=34.3, loss=2.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11, Loss: 2.348786, Accuracy: 34.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #11: 100%|██████████| 8/8 [00:00<00:00, 11.95it/s, accuracy=44.9, loss=1.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.9279, Accuracy: 44.89%\n",
      "Best Accuracy: 44.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #12: 100%|██████████| 990/990 [02:22<00:00,  6.97it/s, accuracy=35.7, loss=2.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12, Loss: 2.290356, Accuracy: 35.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #12: 100%|██████████| 8/8 [00:00<00:00, 12.43it/s, accuracy=38.4, loss=2.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.0624, Accuracy: 38.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #13: 100%|██████████| 990/990 [02:21<00:00,  7.01it/s, accuracy=37.5, loss=2.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13, Loss: 2.232722, Accuracy: 37.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #13: 100%|██████████| 8/8 [00:00<00:00, 12.19it/s, accuracy=44.7, loss=1.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.7950, Accuracy: 44.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #14: 100%|██████████| 990/990 [03:18<00:00,  4.98it/s, accuracy=38.6, loss=2.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14, Loss: 2.187071, Accuracy: 38.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #14: 100%|██████████| 8/8 [00:01<00:00,  7.34it/s, accuracy=46.4, loss=1.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.8467, Accuracy: 46.44%\n",
      "Best Accuracy: 46.44%\n",
      "Change lr:0.010000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #15: 100%|██████████| 990/990 [03:35<00:00,  4.60it/s, accuracy=46.3, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15, Loss: 1.886494, Accuracy: 46.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #15: 100%|██████████| 8/8 [00:01<00:00,  7.66it/s, accuracy=60, loss=1.31]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.3105, Accuracy: 60.00%\n",
      "Best Accuracy: 60.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #16: 100%|██████████| 990/990 [03:35<00:00,  4.59it/s, accuracy=48.6, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16, Loss: 1.793619, Accuracy: 48.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #16: 100%|██████████| 8/8 [00:01<00:00,  7.84it/s, accuracy=60.4, loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2820, Accuracy: 60.44%\n",
      "Best Accuracy: 60.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #17: 100%|██████████| 990/990 [03:36<00:00,  4.58it/s, accuracy=49.6, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17, Loss: 1.747732, Accuracy: 49.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #17: 100%|██████████| 8/8 [00:01<00:00,  7.64it/s, accuracy=60.2, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2571, Accuracy: 60.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #18: 100%|██████████| 990/990 [03:38<00:00,  4.53it/s, accuracy=50.4, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18, Loss: 1.716956, Accuracy: 50.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #18: 100%|██████████| 8/8 [00:01<00:00,  7.87it/s, accuracy=61.1, loss=1.24] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2380, Accuracy: 61.11%\n",
      "Best Accuracy: 61.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #19: 100%|██████████| 990/990 [03:36<00:00,  4.57it/s, accuracy=51.2, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19, Loss: 1.694842, Accuracy: 51.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #19: 100%|██████████| 8/8 [00:01<00:00,  7.94it/s, accuracy=62, loss=1.25]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2507, Accuracy: 62.00%\n",
      "Best Accuracy: 62.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #20: 100%|██████████| 990/990 [03:10<00:00,  5.19it/s, accuracy=51.7, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20, Loss: 1.668227, Accuracy: 51.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #20: 100%|██████████| 8/8 [00:01<00:00,  7.02it/s, accuracy=62.4, loss=1.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2542, Accuracy: 62.44%\n",
      "Best Accuracy: 62.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #21: 100%|██████████| 990/990 [03:20<00:00,  4.95it/s, accuracy=52.6, loss=2.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21, Loss: 1.640695, Accuracy: 52.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #21: 100%|██████████| 8/8 [00:01<00:00,  7.60it/s, accuracy=61.3, loss=1.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2330, Accuracy: 61.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #22: 100%|██████████| 990/990 [03:36<00:00,  4.57it/s, accuracy=52.9, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22, Loss: 1.629080, Accuracy: 52.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #22: 100%|██████████| 8/8 [00:01<00:00,  7.58it/s, accuracy=63.6, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.2082, Accuracy: 63.56%\n",
      "Best Accuracy: 63.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #23: 100%|██████████| 990/990 [03:37<00:00,  4.56it/s, accuracy=53.2, loss=1.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23, Loss: 1.609286, Accuracy: 53.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #23: 100%|██████████| 8/8 [00:01<00:00,  7.87it/s, accuracy=63.6, loss=1.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1740, Accuracy: 63.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #24: 100%|██████████| 990/990 [03:35<00:00,  4.59it/s, accuracy=54, loss=1.42]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24, Loss: 1.586003, Accuracy: 53.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #24: 100%|██████████| 8/8 [00:01<00:00,  7.68it/s, accuracy=64.2, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1927, Accuracy: 64.22%\n",
      "Best Accuracy: 64.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #25: 100%|██████████| 990/990 [03:21<00:00,  4.91it/s, accuracy=54, loss=1.67]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25, Loss: 1.581621, Accuracy: 53.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #25: 100%|██████████| 8/8 [00:00<00:00, 12.54it/s, accuracy=61.8, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1911, Accuracy: 61.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #26: 100%|██████████| 990/990 [02:21<00:00,  7.00it/s, accuracy=54.4, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26, Loss: 1.562532, Accuracy: 54.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #26: 100%|██████████| 8/8 [00:00<00:00, 12.26it/s, accuracy=65.3, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1124, Accuracy: 65.33%\n",
      "Best Accuracy: 65.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #27: 100%|██████████| 990/990 [02:22<00:00,  6.94it/s, accuracy=55.1, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27, Loss: 1.544095, Accuracy: 55.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #27: 100%|██████████| 8/8 [00:00<00:00, 12.55it/s, accuracy=66, loss=1.13]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1327, Accuracy: 66.00%\n",
      "Best Accuracy: 66.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #28: 100%|██████████| 990/990 [02:22<00:00,  6.96it/s, accuracy=55.5, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28, Loss: 1.528778, Accuracy: 55.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #28: 100%|██████████| 8/8 [00:00<00:00, 12.49it/s, accuracy=64.2, loss=1.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1364, Accuracy: 64.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #29: 100%|██████████| 990/990 [02:45<00:00,  6.00it/s, accuracy=55.6, loss=1.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29, Loss: 1.522047, Accuracy: 55.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #29: 100%|██████████| 8/8 [00:00<00:00, 12.36it/s, accuracy=65.1, loss=1.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1225, Accuracy: 65.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #30: 100%|██████████| 990/990 [02:34<00:00,  6.40it/s, accuracy=56.1, loss=1.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30, Loss: 1.503509, Accuracy: 56.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #30: 100%|██████████| 8/8 [00:00<00:00, 12.31it/s, accuracy=63.6, loss=1.13] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.1327, Accuracy: 63.56%\n",
      "Final Best Accuracy: 66.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "# batch_size = 32\n",
    "# test_batch_size = 32\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "net_name = 'dy_resnet'\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch in [epochs*0.5, epochs*0.75, epochs*0.85]:\n",
    "        for p in optimizer.param_groups:\n",
    "            p['lr'] *= 0.1\n",
    "            lr = p['lr']\n",
    "        print('Change lr:'+str(lr))\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    train_acc = 0.\n",
    "    adjust_lr(optimizer, epoch)\n",
    "    train_loader_len = len(train_loader.dataset)\n",
    "    train_loader_iter = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training Epoch #{}\".format(epoch))\n",
    "    \n",
    "    for batch_idx, (data, target) in train_loader_iter:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        avg_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loader_iter.set_postfix(loss=loss.item(), accuracy=100. * train_acc.item() / train_loader_len)\n",
    "    \n",
    "    print('Train Epoch: {}, Loss: {:.6f}, Accuracy: {:.2f}%'.format(epoch, avg_loss / len(train_loader), 100. * train_acc / train_loader_len))\n",
    "\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    val_loader_iter = tqdm(val_loader, total=len(val_loader), desc=\"Validation Epoch #{}\".format(epoch))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader_iter:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, label, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "            val_loader_iter.set_postfix(loss=test_loss / len(val_loader.dataset), accuracy=100. * correct.item() / len(val_loader.dataset))\n",
    "    \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('Validation Set: Average Loss: {:.4f}, Accuracy: {:.2f}%'.format(test_loss, accuracy))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "if is_train:\n",
    "    best_val_acc = 0.\n",
    "    for i in range(epochs):\n",
    "        train(i + 1)\n",
    "        temp_acc = val(i + 1)\n",
    "        if temp_acc > best_val_acc:\n",
    "            best_val_acc = temp_acc\n",
    "            torch.save(model.state_dict(), 'best_1.pt')\n",
    "            print('Best Accuracy: {:.2f}%'.format(best_val_acc))\n",
    "\n",
    "    print('Final Best Accuracy: {:.2f}%'.format(best_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入DynamicConv2D ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): DynamicConv2D()\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = DynamicConv2D(in_channels=3, out_channels=64, kernel_size=7, padding=1)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 50)\n",
    "model.load_state_dict(torch.load(\"best_1.pt\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_channels(image, channels='RGB'):\n",
    "    if channels == 'R':\n",
    "        return image[0, :, :].unsqueeze(0)\n",
    "    elif channels == 'G':\n",
    "        return image[1, :, :].unsqueeze(0)\n",
    "    elif channels == 'B':\n",
    "        return image[2, :, :].unsqueeze(0)\n",
    "    elif channels == 'RG':\n",
    "        return image[0:2, :, :]\n",
    "    elif channels == 'RB':\n",
    "        return torch.stack([image[0, :, :], image[2, :, :]], dim=0)\n",
    "    elif channels == 'GB':\n",
    "        return image[1:, :, :]\n",
    "    elif channels == 'RGB':\n",
    "        return image\n",
    "    else:\n",
    "        raise ValueError('Invalid channel selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_dataloader(set_channel = 'RGB'):\n",
    "    test_augmentations = transforms.Compose([\n",
    "        transforms.Resize(96),\n",
    "        transforms.CenterCrop(96),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.Lambda(lambda x: select_channels(x, set_channel))  # Change 'RGB' to other combinations as needed\n",
    "    ])\n",
    "\n",
    "    test_dataset = ImageNetDataset(data_file='test.txt', root_dir='', transform=test_augmentations)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試集驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00,  9.87it/s, accuracy=69.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: RGB, Accuracy: 69.56%, Precision: 71.25%, Recall: 69.56%, F1 Score: 68.36%, FLOPS: 1274698880, Elapsed Time: 0.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 12.19it/s, accuracy=57.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: RG, Accuracy: 57.33%, Precision: 61.72%, Recall: 57.33%, F1 Score: 56.81%, FLOPS: 1248155776, Elapsed Time: 0.66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 11.59it/s, accuracy=56.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: RB, Accuracy: 56.89%, Precision: 60.93%, Recall: 56.89%, F1 Score: 56.26%, FLOPS: 1248155776, Elapsed Time: 0.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 10.61it/s, accuracy=53.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: GB, Accuracy: 53.78%, Precision: 57.50%, Recall: 53.78%, F1 Score: 52.75%, FLOPS: 1248155776, Elapsed Time: 0.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 11.14it/s, accuracy=24.4]\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: R, Accuracy: 24.44%, Precision: 34.60%, Recall: 24.44%, F1 Score: 21.76%, FLOPS: 1221612672, Elapsed Time: 0.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 10.87it/s, accuracy=22.2]\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: G, Accuracy: 22.22%, Precision: 31.10%, Recall: 22.22%, F1 Score: 20.10%, FLOPS: 1221612672, Elapsed Time: 0.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 10.74it/s, accuracy=21.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Set: B, Accuracy: 21.33%, Precision: 26.59%, Recall: 21.33%, F1 Score: 17.88%, FLOPS: 1221612672, Elapsed Time: 0.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def test(model, rgb_set):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loader = rgb_dataloader(set_channel = rgb_set)\n",
    "    test_loader_len = len(test_loader.dataset)\n",
    "    test_loader_iter = tqdm(test_loader, total=len(test_loader), desc=\"Testing\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_iter:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            \n",
    "            test_loader_iter.set_postfix(accuracy=100. * correct.item() / test_loader_len)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    accuracy = 100. * correct / test_loader_len\n",
    "    \n",
    "    # 計算 Precision, Recall 和 F1-score\n",
    "    precision = 100. * precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = 100. * recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = 100. * f1_score(all_targets, all_preds, average='macro')\n",
    "    \n",
    "    # 計算 FLOPS\n",
    "    flops = torchprofile.profile_macs(model, torch.randn(1, *data.shape[1:]).to(device))\n",
    "    \n",
    "    return accuracy.item(), precision, recall, f1, flops, elapsed_time\n",
    "\n",
    "rgb_list = [\"RGB\", \"RG\", \"RB\", \"GB\", \"R\", \"G\", \"B\"]\n",
    "for rgb in rgb_list:\n",
    "    resnet_acc, resnet_precision, resnet_recall, resnet_f1, resnet_flops, resnet_elapsed_time = test(model,rgb)\n",
    "    print(f\"RGB Set: {rgb:s}, Accuracy: {resnet_acc:.2f}%, Precision: {resnet_precision:.2f}%, Recall: {resnet_recall:.2f}%, F1 Score: {resnet_f1:.2f}%, FLOPS: {resnet_flops:d}, Elapsed Time: {resnet_elapsed_time:.2f} seconds\")\n",
    "    # resnet18_acc, resnet18_elapsed_time = test(model,rgb)\n",
    "    # print(f\"RGB Set: {rgb:s}, Accuracy: {resnet18_acc:.2f}%, Elapsed Time: {resnet18_elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 50)\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #1: 100%|██████████| 990/990 [02:17<00:00,  7.22it/s, accuracy=3.14, loss=3.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Loss: 3.901848, Accuracy: 3.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #1: 100%|██████████| 8/8 [00:00<00:00, 12.61it/s, accuracy=4.89, loss=3.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.7242, Accuracy: 4.89%\n",
      "Best Accuracy: 4.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #2: 100%|██████████| 990/990 [01:57<00:00,  8.43it/s, accuracy=5.26, loss=3.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2, Loss: 3.763737, Accuracy: 5.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #2: 100%|██████████| 8/8 [00:00<00:00, 12.69it/s, accuracy=10.7, loss=3.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.5248, Accuracy: 10.67%\n",
      "Best Accuracy: 10.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #3: 100%|██████████| 990/990 [02:59<00:00,  5.53it/s, accuracy=7.83, loss=3.54] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3, Loss: 3.611340, Accuracy: 7.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #3: 100%|██████████| 8/8 [00:00<00:00,  8.39it/s, accuracy=13.6, loss=3.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.3712, Accuracy: 13.56%\n",
      "Best Accuracy: 13.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #4: 100%|██████████| 990/990 [03:22<00:00,  4.90it/s, accuracy=10.4, loss=3.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4, Loss: 3.485261, Accuracy: 10.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #4: 100%|██████████| 8/8 [00:00<00:00,  8.02it/s, accuracy=14.9, loss=3.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.1847, Accuracy: 14.89%\n",
      "Best Accuracy: 14.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #5: 100%|██████████| 990/990 [03:22<00:00,  4.89it/s, accuracy=12.1, loss=3.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5, Loss: 3.390229, Accuracy: 12.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #5: 100%|██████████| 8/8 [00:00<00:00,  8.08it/s, accuracy=20.7, loss=3.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 3.0821, Accuracy: 20.67%\n",
      "Best Accuracy: 20.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #6: 100%|██████████| 990/990 [03:22<00:00,  4.90it/s, accuracy=13.8, loss=3.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6, Loss: 3.297329, Accuracy: 13.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #6: 100%|██████████| 8/8 [00:00<00:00,  8.02it/s, accuracy=21.6, loss=2.95] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.9524, Accuracy: 21.56%\n",
      "Best Accuracy: 21.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #7: 100%|██████████| 990/990 [02:37<00:00,  6.30it/s, accuracy=15.6, loss=3.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7, Loss: 3.212652, Accuracy: 15.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #7: 100%|██████████| 8/8 [00:00<00:00, 13.08it/s, accuracy=18.9, loss=2.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.8989, Accuracy: 18.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #8: 100%|██████████| 990/990 [02:02<00:00,  8.11it/s, accuracy=17.7, loss=3.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8, Loss: 3.121726, Accuracy: 17.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #8: 100%|██████████| 8/8 [00:00<00:00, 12.56it/s, accuracy=26, loss=2.74]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.7386, Accuracy: 26.00%\n",
      "Best Accuracy: 26.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #9: 100%|██████████| 990/990 [02:05<00:00,  7.90it/s, accuracy=19.4, loss=3.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9, Loss: 3.035861, Accuracy: 19.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #9: 100%|██████████| 8/8 [00:00<00:00,  8.28it/s, accuracy=26.9, loss=2.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.5941, Accuracy: 26.89%\n",
      "Best Accuracy: 26.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #10: 100%|██████████| 990/990 [03:15<00:00,  5.06it/s, accuracy=20.8, loss=3.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10, Loss: 2.962334, Accuracy: 20.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #10: 100%|██████████| 8/8 [00:00<00:00,  8.16it/s, accuracy=31.6, loss=2.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.5236, Accuracy: 31.56%\n",
      "Best Accuracy: 31.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #11: 100%|██████████| 990/990 [02:41<00:00,  6.15it/s, accuracy=22.2, loss=2.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11, Loss: 2.887143, Accuracy: 22.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #11: 100%|██████████| 8/8 [00:00<00:00, 13.13it/s, accuracy=27.8, loss=2.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.6422, Accuracy: 27.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #12: 100%|██████████| 990/990 [03:05<00:00,  5.35it/s, accuracy=23.6, loss=2.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12, Loss: 2.835069, Accuracy: 23.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #12: 100%|██████████| 8/8 [00:01<00:00,  7.99it/s, accuracy=31.3, loss=2.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.4353, Accuracy: 31.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #13: 100%|██████████| 990/990 [02:29<00:00,  6.64it/s, accuracy=25.1, loss=2.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13, Loss: 2.771141, Accuracy: 25.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #13: 100%|██████████| 8/8 [00:00<00:00, 13.29it/s, accuracy=32.2, loss=2.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.3727, Accuracy: 32.22%\n",
      "Best Accuracy: 32.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #14: 100%|██████████| 990/990 [03:06<00:00,  5.32it/s, accuracy=25.8, loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14, Loss: 2.729147, Accuracy: 25.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #14: 100%|██████████| 8/8 [00:00<00:00,  8.10it/s, accuracy=34.2, loss=2.34] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 2.3397, Accuracy: 34.22%\n",
      "Best Accuracy: 34.22%\n",
      "Change lr:0.010000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #15: 100%|██████████| 990/990 [03:18<00:00,  4.98it/s, accuracy=32.1, loss=2.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15, Loss: 2.457023, Accuracy: 32.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #15: 100%|██████████| 8/8 [00:01<00:00,  7.99it/s, accuracy=43.6, loss=1.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.9415, Accuracy: 43.56%\n",
      "Best Accuracy: 43.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #16: 100%|██████████| 990/990 [03:19<00:00,  4.96it/s, accuracy=34.4, loss=2.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16, Loss: 2.360078, Accuracy: 34.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #16: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s, accuracy=44.4, loss=1.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.8753, Accuracy: 44.44%\n",
      "Best Accuracy: 44.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #17: 100%|██████████| 990/990 [02:28<00:00,  6.68it/s, accuracy=35.4, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17, Loss: 2.319121, Accuracy: 35.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #17: 100%|██████████| 8/8 [00:00<00:00, 13.13it/s, accuracy=46.2, loss=1.83] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.8276, Accuracy: 46.22%\n",
      "Best Accuracy: 46.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #18: 100%|██████████| 990/990 [03:05<00:00,  5.33it/s, accuracy=36.2, loss=2.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18, Loss: 2.282511, Accuracy: 36.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #18: 100%|██████████| 8/8 [00:00<00:00,  8.35it/s, accuracy=46.7, loss=1.82] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.8194, Accuracy: 46.67%\n",
      "Best Accuracy: 46.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #19: 100%|██████████| 990/990 [03:16<00:00,  5.04it/s, accuracy=36.8, loss=2.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19, Loss: 2.259003, Accuracy: 36.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #19: 100%|██████████| 8/8 [00:00<00:00,  8.28it/s, accuracy=46.4, loss=1.81] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.8087, Accuracy: 46.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #20: 100%|██████████| 990/990 [03:02<00:00,  5.43it/s, accuracy=37.5, loss=2.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20, Loss: 2.234407, Accuracy: 37.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #20: 100%|██████████| 8/8 [00:00<00:00,  8.03it/s, accuracy=46.9, loss=1.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.7513, Accuracy: 46.89%\n",
      "Best Accuracy: 46.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #21: 100%|██████████| 990/990 [03:12<00:00,  5.14it/s, accuracy=38.1, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21, Loss: 2.210109, Accuracy: 38.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #21: 100%|██████████| 8/8 [00:00<00:00,  8.30it/s, accuracy=48, loss=1.72]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.7163, Accuracy: 48.00%\n",
      "Best Accuracy: 48.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #22: 100%|██████████| 990/990 [02:56<00:00,  5.62it/s, accuracy=38.6, loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22, Loss: 2.191827, Accuracy: 38.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #22: 100%|██████████| 8/8 [00:00<00:00, 10.73it/s, accuracy=45.8, loss=1.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.7388, Accuracy: 45.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #23: 100%|██████████| 990/990 [02:53<00:00,  5.69it/s, accuracy=39.1, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23, Loss: 2.166717, Accuracy: 39.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #23: 100%|██████████| 8/8 [00:01<00:00,  7.69it/s, accuracy=50.7, loss=1.73] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.7311, Accuracy: 50.67%\n",
      "Best Accuracy: 50.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #24: 100%|██████████| 990/990 [02:22<00:00,  6.93it/s, accuracy=39.8, loss=2.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24, Loss: 2.141939, Accuracy: 39.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #24: 100%|██████████| 8/8 [00:01<00:00,  7.75it/s, accuracy=49.8, loss=1.67] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.6696, Accuracy: 49.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #25: 100%|██████████| 990/990 [02:04<00:00,  7.92it/s, accuracy=40.2, loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25, Loss: 2.121580, Accuracy: 40.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #25: 100%|██████████| 8/8 [00:00<00:00, 13.22it/s, accuracy=50, loss=1.67]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.6669, Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #26: 100%|██████████| 990/990 [02:29<00:00,  6.62it/s, accuracy=40.5, loss=2.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26, Loss: 2.109546, Accuracy: 40.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #26: 100%|██████████| 8/8 [00:01<00:00,  7.21it/s, accuracy=50, loss=1.67]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.6677, Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #27: 100%|██████████| 990/990 [02:09<00:00,  7.64it/s, accuracy=41.3, loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27, Loss: 2.081334, Accuracy: 41.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #27: 100%|██████████| 8/8 [00:00<00:00, 13.36it/s, accuracy=50.9, loss=1.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.6457, Accuracy: 50.89%\n",
      "Best Accuracy: 50.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #28: 100%|██████████| 990/990 [02:12<00:00,  7.48it/s, accuracy=41.5, loss=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28, Loss: 2.076736, Accuracy: 41.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #28: 100%|██████████| 8/8 [00:00<00:00, 12.32it/s, accuracy=52.7, loss=1.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.5749, Accuracy: 52.67%\n",
      "Best Accuracy: 52.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #29: 100%|██████████| 990/990 [02:08<00:00,  7.72it/s, accuracy=41.9, loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29, Loss: 2.068666, Accuracy: 41.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #29: 100%|██████████| 8/8 [00:00<00:00, 13.56it/s, accuracy=50, loss=1.65]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.6510, Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch #30: 100%|██████████| 990/990 [02:01<00:00,  8.17it/s, accuracy=42.2, loss=2.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30, Loss: 2.041643, Accuracy: 42.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch #30: 100%|██████████| 8/8 [00:00<00:00, 13.27it/s, accuracy=51.3, loss=1.58] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Average Loss: 1.5810, Accuracy: 51.33%\n",
      "Final Best Accuracy: 52.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "# batch_size = 32\n",
    "# test_batch_size = 32\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch in [epochs*0.5, epochs*0.75, epochs*0.85]:\n",
    "        for p in optimizer.param_groups:\n",
    "            p['lr'] *= 0.1\n",
    "            lr = p['lr']\n",
    "        print('Change lr:'+str(lr))\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    train_acc = 0.\n",
    "    adjust_lr(optimizer, epoch)\n",
    "    train_loader_len = len(train_loader.dataset)\n",
    "    train_loader_iter = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training Epoch #{}\".format(epoch))\n",
    "    \n",
    "    for batch_idx, (data, target) in train_loader_iter:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        avg_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loader_iter.set_postfix(loss=loss.item(), accuracy=100. * train_acc.item() / train_loader_len)\n",
    "    \n",
    "    print('Train Epoch: {}, Loss: {:.6f}, Accuracy: {:.2f}%'.format(epoch, avg_loss / len(train_loader), 100. * train_acc / train_loader_len))\n",
    "\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    val_loader_iter = tqdm(val_loader, total=len(val_loader), desc=\"Validation Epoch #{}\".format(epoch))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader_iter:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, label, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "            val_loader_iter.set_postfix(loss=test_loss / len(val_loader.dataset), accuracy=100. * correct.item() / len(val_loader.dataset))\n",
    "    \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('Validation Set: Average Loss: {:.4f}, Accuracy: {:.2f}%'.format(test_loss, accuracy))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "if is_train:\n",
    "    best_val_acc = 0.\n",
    "    for i in range(epochs):\n",
    "        train(i + 1)\n",
    "        temp_acc = val(i + 1)\n",
    "        if temp_acc > best_val_acc:\n",
    "            best_val_acc = temp_acc\n",
    "            torch.save(model.state_dict(), 'resnet18_best.pt')\n",
    "            print('Best Accuracy: {:.2f}%'.format(best_val_acc))\n",
    "\n",
    "    print('Final Best Accuracy: {:.2f}%'.format(best_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入訓練好ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wen\\anaconda3\\envs\\wen\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_model = models.resnet18(pretrained=False)\n",
    "resnet18_model.fc = torch.nn.Linear(model.fc.in_features, 50)\n",
    "resnet18_model.load_state_dict(torch.load(\"resnet18_best.pt\"))\n",
    "resnet18_model.to(device)\n",
    "resnet18_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_augmentations = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = ImageNetDataset(data_file='test.txt', root_dir='', transform=test_augmentations)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 12.99it/s, accuracy=51.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.33%, Precision: 52.68%, Recall: 51.33%, F1 Score: 50.48%, FLOPS: 333585408, Elapsed Time: 0.62 seconds\n"
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loader_len = len(test_loader.dataset)\n",
    "    test_loader_iter = tqdm(test_loader, total=len(test_loader), desc=\"Testing\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_iter:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            \n",
    "            test_loader_iter.set_postfix(accuracy=100. * correct.item() / test_loader_len)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    accuracy = 100. * correct / test_loader_len\n",
    "    \n",
    "    # 計算 Precision, Recall 和 F1-score\n",
    "    precision = 100. * precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = 100. * recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = 100. * f1_score(all_targets, all_preds, average='macro')\n",
    "    \n",
    "    # 計算 FLOPS\n",
    "    flops = torchprofile.profile_macs(model, torch.randn(1, *data.shape[1:]).to(device))\n",
    "    \n",
    "    return accuracy.item(), precision, recall, f1, flops, elapsed_time\n",
    "\n",
    "resnet_acc, resnet_precision, resnet_recall, resnet_f1, resnet_flops, resnet_elapsed_time = test(resnet18_model)\n",
    "print(f\"Accuracy: {resnet_acc:.2f}%, Precision: {resnet_precision:.2f}%, Recall: {resnet_recall:.2f}%, F1 Score: {resnet_f1:.2f}%, FLOPS: {resnet_flops:d}, Elapsed Time: {resnet_elapsed_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
